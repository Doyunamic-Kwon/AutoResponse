require('dotenv').config();
const express = require('express');
const cors = require('cors');
const morgan = require('morgan');
const path = require('path');
const fs = require('fs-extra');
const OpenAI = require('openai');

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const app = express();
const PORT = process.env.PORT || 4000;

app.use(cors());
app.use(express.json());
app.use(morgan('dev'));

// Paths
const dataDir = path.join(__dirname, '../../scraper/data');
console.log(`[BACKEND] Data directory: ${dataDir}`);

// Routes preview
app.get('/', (req, res) => {
    res.json({ message: "AutoResponse API is running" });
});

// Endpoint to get the latest reviews
app.get('/api/reviews', async (req, res) => {
    try {
        const files = await fs.readdir(dataDir);
        const jsonFiles = files.filter(f => f.endsWith('.json') && f.startsWith('reviews_'));

        if (jsonFiles.length === 0) {
            return res.json({ reviews: [], message: "No review files found." });
        }

        // Sort by name (which includes timestamp) to get the latest
        jsonFiles.sort().reverse();
        const latestFile = path.join(dataDir, jsonFiles[0]);

        const data = await fs.readJson(latestFile);
        res.json(data);
    } catch (error) {
        console.error(error);
        res.status(500).json({ error: "Failed to load reviews" });
    }
});

// AI Reply Generation Endpoint
// AI Reply Generation Endpoint
app.post('/api/generate-reply', async (req, res) => {
    const { content, source, reviewer, waiting, purpose, visitTime, booking, reviewType, style = 'warm' } = req.body;

    if (!content && !purpose) {
        return res.status(400).json({ error: "Review content or context is required" });
    }

    try {
        const personas = {
            warm: "í–‡ì‚´ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ì¹œì ˆí•œ ì¹´íŽ˜ ì‚¬ìž¥ë‹˜. 'ì˜¨ê¸°'ì™€ 'ì •ì„±'ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ë©°, ì†ë‹˜ì˜ ë¦¬ë·°ë¥¼ í•˜ë‚˜í•˜ë‚˜ ê¹Šì´ ê³µê°í•˜ê³  ë°°ë ¤í•˜ëŠ” ë§íˆ¬(ì˜ˆ: ~í•˜ì…¨êµ°ìš”, ~ë•ë¶„ì— ì €í¬ë„ í–‰ë³µí–ˆìŠµë‹ˆë‹¤)ë¥¼ ì‚¬ìš©í•¨.",
            professional: "ì‹ ë¢°ê°ì„ ì£¼ëŠ” ëƒ‰ì² í•˜ë©´ì„œë„ ì˜ˆì˜ ë°”ë¥¸ ë§¤ë‹ˆì €. êµ°ë”ë”ê¸° ì—†ì´ ê¹”ë”í•˜ê³  ì „ë¬¸ì ì¸ ë¬¸ì²´(ì˜ˆ: ~ìž…ë‹ˆë‹¤, ~í•˜ê² ìŠµë‹ˆë‹¤)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸Œëžœë“œì˜ ì‹ ë¢°ë„ë¥¼ ë†’ìž„.",
            energetic: "ì—ë„ˆì§€ê°€ ë„˜ì¹˜ê³  ìœ„íŠ¸ ìžˆëŠ” ì‚¬ìž¥ë‹˜. ëŠë‚Œí‘œ(!)ì™€ ì´ëª¨ì§€ë¥¼ ì ì ˆížˆ ì‚¬ìš©í•˜ì—¬ ì†ë‹˜ì—ê²Œ í™œê¸°ë¥¼ ì „ë‹¬í•˜ê³  ì¹œê·¼í•˜ê²Œ ì†Œí†µí•¨(ì˜ˆ: ìš°ì™€! ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤!)"
        };

        const selectedPersona = personas[style] || personas.warm;

        const contextInfo = [];
        if (visitTime) contextInfo.push(`ë°©ë¬¸ ì‹œê°„: ${visitTime}`);
        if (booking) contextInfo.push(`ì˜ˆì•½ ì •ë³´: ${booking}`);
        if (waiting) contextInfo.push(`ëŒ€ê¸° ìƒí™©: ${waiting}`);
        if (purpose) contextInfo.push(`ë°©ë¬¸ ëª©ì : ${purpose}`);
        if (reviewType) contextInfo.push(`ì¸ì¦ ìœ í˜•: ${reviewType}`);

        const systemMessage = `ë„ˆëŠ” ${selectedPersona}ì´ì•¼.
ê³ ê°ì´ ë‚¨ê¸´ ë¦¬ë·°ì— ëŒ€í•´ 'ì‚¬ëžŒì´ ì§ì ‘ ì“´ ê²ƒ ê°™ì€' ë”°ëœ»í•˜ê³  ìžì—°ìŠ¤ëŸ¬ìš´ ë‹µê¸€ì„ ìž‘ì„±í•´ì¤˜.
íŠ¹ížˆ ë‹¤ìŒ 'ìƒí™© ì •ë³´'ë¥¼ ìµœëŒ€í•œ ìžì—°ìŠ¤ëŸ½ê²Œ ë¬¸ìž¥ ì†ì— ë…¹ì—¬ë‚´ì„œ, ë‹¨ìˆœížˆ í…œí”Œë¦¿ì„ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼ëŠ” ì ì„ ë³´ì—¬ì¤˜.
(ì˜ˆ: "ì˜¤í›„ì— ë°©ë¬¸í•´ ì£¼ì…¨ëŠ”ë° ëŒ€ê¸° ì—†ì´ ë°”ë¡œ ìž…ìž¥í•˜ì…¨ë‹¤ë‹ˆ ì •ë§ ë‹¤í–‰ì´ë„¤ìš”!")

[ê·œì¹™]
1. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ê³ , 3~4ë¬¸ìž¥ ì •ë„ë¡œ ì •ì¤‘í•˜ê²Œ ìž‘ì„±í•  ê²ƒ.
2. AIì¸ í‹°ê°€ ë‚˜ì§€ ì•Šë„ë¡ ë¡œë´‡ ê°™ì€ í‘œí˜„ì´ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ë°˜ë³µì ì¸ í‘œí˜„ì€ í”¼í•  ê²ƒ.
3. ë¦¬ë·° ë‚´ìš©ì´ ì—†ë”ë¼ë„ 'ìƒí™© ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ "ë°©ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤" ì‹ì˜ ì •ì„±ìŠ¤ëŸ¬ìš´ ì¸ì‚¬ë¥¼ ê±´ë„¬ ê²ƒ.`;

        const userMessage = `[ì •ë³´]
í”Œëž«í¼: ${source}
ìž‘ì„±ìž: ${reviewer || 'ê³ ê°ë‹˜'}
ìƒí™© ì •ë³´: ${contextInfo.join(', ') || 'ì •ë³´ ì—†ìŒ'}
ë¦¬ë·° ë‚´ìš©: ${content || 'ë‚´ìš© ì—†ìŒ (í‚¤ì›Œë“œ/ë³„ì  ë¦¬ë·°)'}`;

        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
                { role: "system", content: systemMessage },
                { role: "user", content: userMessage }
            ],
            temperature: 0.8,
        });

        const reply = response.choices[0].message.content;
        res.json({ reply });
    } catch (error) {
        console.error("OpenAI Error:", error);
        res.status(500).json({ error: "AI ë‹µê¸€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”." });
    }
});

// AI Insights Endpoint
app.get('/api/insights', async (req, res) => {
    try {
        const files = await fs.readdir(dataDir);
        const jsonFiles = files.filter(f => f.endsWith('.json') && f.startsWith('reviews_'));

        if (jsonFiles.length === 0) {
            return res.json({ summary: "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", keywords: [] });
        }

        jsonFiles.sort().reverse();
        const latestFile = path.join(dataDir, jsonFiles[0]);
        const data = await fs.readJson(latestFile);

        const allReviews = [...(data.naver || []), ...(data.kakao || [])];
        const textToAnalyze = allReviews
            .filter(r => r.content && r.content.length > 5)
            .map(r => `[í‰ì : ${r.rating}] ${r.content}`)
            .slice(0, 20) // Limit to latest 20 for token saving
            .join('\n');

        if (!textToAnalyze) {
            return res.json({
                summary: "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ë·°ê°€ ì•„ì§ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                keywords: ["ë°ì´í„° ë¶€ì¡±"]
            });
        }

        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
                {
                    role: "system",
                    content: "ë„ˆëŠ” ì‹ë‹¹ í‰íŒ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë¦¬ë·°ë“¤ì„ ë¶„ì„í•´ì„œ 'ë§¤ìž¥ì˜ í˜„ìž¬ ìƒíƒœ í•œì¤„ ìš”ì•½'ê³¼ 'í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ'ë¥¼ ì¶”ì¶œí•´ì¤˜. í‚¤ì›Œë“œëŠ” ê¸ì •/ë¶€ì • ì„žì–´ì„œ ê°€ìž¥ ë‘ë“œëŸ¬ì§€ëŠ” ê²ƒìœ¼ë¡œ ë½‘ì•„ì¤˜. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´: { \"summary\": \"string\", \"keywords\": [\"string\"] }"
                },
                { role: "user", content: `ë¦¬ë·° ë°ì´í„°:\n${textToAnalyze}` }
            ],
            response_format: { type: "json_object" },
            temperature: 0.7,
        });

        const insights = JSON.parse(response.choices[0].message.content);
        res.json(insights);
    } catch (error) {
        console.error("Insight Generation Error:", error);
        res.status(500).json({ error: "ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨" });
    }
});

// SSE Clients collection
let clients = [];

// Broadcast to all connected clients
const broadcast = (data) => {
    clients.forEach(client => client.res.write(`data: ${JSON.stringify(data)}\n\n`));
};

// SSE Streaming Endpoint
app.get('/api/sync-stream', (req, res) => {
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.flushHeaders();

    const clientId = Date.now();
    const newClient = { id: clientId, res };
    clients.push(newClient);

    console.log(`[SSE] Client connected: ${clientId}`);

    req.on('close', () => {
        console.log(`[SSE] Client disconnected: ${clientId}`);
        clients = clients.filter(c => c.id !== clientId);
    });
});

// Real-time Sync Endpoint (Trigger Scraper)
app.post('/api/sync', async (req, res) => {
    const { naver, kakao, naverId, kakaoId } = req.body;

    const nId = naver || naverId;
    const kId = kakao || kakaoId;

    if (!nId || !kId) {
        return res.status(400).json({ error: "Both Naver and Kakao IDs are required" });
    }

    const { spawn } = require('child_process');
    const scraperPath = path.join(__dirname, '../../scraper/src/main.js');

    console.log(`[BACKEND] Triggering live sync for Naver: ${nId}, Kakao: ${kId}`);
    broadcast({ type: 'status', message: 'ðŸš€ Scraper initialized...' });

    const scraper = spawn('node', [scraperPath, nId, kId]);

    scraper.stdout.on('data', (data) => {
        const message = data.toString().trim();
        if (message) {
            console.log(`[SCRAPER] ${message}`);
            broadcast({ type: 'log', message });
        }
    });

    scraper.stderr.on('data', (data) => {
        const message = data.toString().trim();
        console.error(`[SCRAPER ERR] ${message}`);
        broadcast({ type: 'error', message });
    });

    scraper.on('close', (code) => {
        console.log(`[SCRAPER] Process exited with code ${code}`);
        broadcast({
            type: 'done',
            message: code === 0 ? 'âœ… Sync completed successfully!' : `âŒ Scraper exited with code ${code}`,
            success: code === 0
        });
    });

    res.json({ message: "Scraper process started." });
});

if (process.env.NODE_ENV !== 'test') {
    app.listen(PORT, () => {
        console.log(`[BACKEND] Server is running on http://localhost:${PORT}`);
    });
}

module.exports = app;
